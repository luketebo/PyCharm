## NNLM 优点

+ NNLM 相比于N-gram语言模型不需要事先计算保存所有的概率，而是通过函数计算得到;
+ NNLM 增加单词词向量，利用神经网络求解最优参数以及Softmax的使用，相比N-gram可以更加平滑的预测序列单词的联合概率

问题：

    它只能输入特定长度的上下文（窗口数：N)，也就是说，要自己控制N的输入

## RNNLM

循环神经网络之前是专门用来处理序列化数据的，它对于输入数据没有要求，RNNLM

核心思想：上一步信息通过循环传递给下一步，循环神经网络可以看成同一个网络的多次重复，每次传递一个信息给下一级

可以真正充分地利用所有上下文信息来预测下一个词，从形式上了，这是一个非常理想的模型，它能够用到文本的所有信息

优点：

+ 可以处理任意长度输入
+ 理论上可以追溯前面时间步的信息
+ 模型参数大小固定，与输入长度无关

缺点：

+ 计算时间长
+ 实际应用中，难以追溯很久远的时间步的信息 梯度消失的原因

## 评价指标
